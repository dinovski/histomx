del<-scale(train_norm_top, center=T, scale=F)
dle[1:5,]
del[,1:5]
del[1:5,1:5]
del[1:5,1:5]
train_norm_top[1:5,1:5]
?RUVg
RUVg
RUVg()
##------------------------
## fit final regularized glm on weighted genes
set.seed(181)
glmnet.model <- train(x=train_norm_top,
y=train_norm_labels$class[match(rownames(train_norm_top), train_norm_labels$ID)],
preProc = c("center", "scale"),
method='glmnet', family="binomial",
trControl=fit.control,
tuneGrid=ensemble.tune$glmnet$bestTune)
save(glmnet.model, file=paste0(outPath, "/normal_model_glmnet.rda"))
outPath
set.seed(181)
rf.model <- train(x=train_norm_top,
y=train_norm_labels$class[match(rownames(train_norm_top), train_norm_labels$ID)],
preProc = c("center", "scale"),
method='rf',
trControl=fit.control,
tuneGrid=expand.grid(ensemble.tune$rf$bestTune))
save(rf.model, file=paste0(outPath, "/normal_model_rf.rda"))
##------------------------
## C5.0
ensemble.tune$C5.0$bestTune
set.seed(181)
c5.model <- train(x=train_norm_top,
y=train_norm_labels$class[match(rownames(train_norm_top), train_norm_labels$ID)],
preProc = c("center", "scale"),
method='C5.0',
trControl=fit.control,
tuneGrid=expand.grid(ensemble.tune$C5.0$bestTune))
save(c5.model, file=paste0(outPath, "/normal_model_c5.rda"))
##------------------------
## LDA
set.seed(181)
lda.model <- train(x=train_norm_top,
y=train_norm_labels$class[match(rownames(train_norm_top), train_norm_labels$ID)],
preProc = c("center", "scale"),
method='lda', family='binomial',
trControl=fit.control)
save(lda.model, file=paste0(outPath, "/normal_model_lda.rda"))
##------------------------
## svmRadial
set.seed(181)
svmradial.model <- train(x=train_norm_top,
y=train_norm_labels$class[match(rownames(train_norm_top), train_norm_labels$ID)],
preProc = c("center", "scale"),
method='svmRadial',
trControl=fit.control,
tuneGrid=expand.grid(ensemble.tune$svmRadial$bestTune))
save(svmradial.model, file=paste0(outPath, "/normal_model_svmradial.rda"))
##------------------------
## svmLinear
set.seed(181)
svmlinear.model <- train(x=train_norm_top,
y=train_norm_labels$class[match(rownames(train_norm_top), train_norm_labels$ID)],
preProc = c("center", "scale"),
method='svmLinear',
trControl=fit.control,
tuneGrid=expand.grid(ensemble.tune$svmLinear$bestTune))
save(svmlinear.model, file=paste0(outPath, "/normal_model_svmlinear.rda"))
##------------------------
## KNN
set.seed(181)
knn.model <- train(x=train_norm_top,
y=train_norm_labels$class[match(rownames(train_norm_top), train_norm_labels$ID)],
preProc = c("center", "scale"),
method='knn',
trControl=fit.control,
tuneGrid=expand.grid(ensemble.tune$knn$bestTune))
save(knn.model, file=paste0(outPath, "/normal_model_knn.rda"))
##------------------------
## gradient boosting
set.seed(181)
gbm.model <- train(x=train_norm_top,
y=train_norm_labels$class[match(rownames(train_norm_top), train_norm_labels$ID)],
preProc = c("center", "scale"),
method='gbm',
trControl=fit.control,
tuneGrid=expand.grid(ensemble.tune$gbm$bestTune))
save(gbm.model, file=paste0(outPath, "/normal_model_gbm.rda"))
##------------------------
## extreme gradient boosting linear
set.seed(181)
xgblinear.model <- train(x=train_norm_top,
y=train_norm_labels$class[match(rownames(train_norm_top), train_norm_labels$ID)],
preProc = c("center", "scale"),
method='xgbLinear',
trControl=fit.control,
tuneGrid=expand.grid(ensemble.tune$xgbLinear$bestTune))
save(xgblinear.model, file=paste0(outPath, "/normal_model_xgblinear.rda"))
##------------------------
## extreme gradient boosting tree
set.seed(181)
xgbtree.model <- train(x=train_norm_top,
y=train_norm_labels$class[match(rownames(train_norm_top), train_norm_labels$ID)],
preProc = c("center", "scale"),
method='xgbTree',
trControl=fit.control,
tuneGrid=expand.grid(ensemble.tune$xgbTree$bestTune))
save(xgbtree.model, file=paste0(outPath, "/normal_model_xgbtree.rda"))
scriptsPath="~/Dropbox/PTG/transcriptomics/nanostring/scripts/BHOTR/scripts/"
source(paste0(scriptsPath, 'BHOT.R'))
## load normalized train/test data
source(paste0(scriptsPath, '02_norm.R'))
modelPath=paste0(outPath, "/preproc/tcmr_model")
outPath=paste0(outPath, "/model_eval/preproc/")
dir.create(outPath)
glmnet.model <- get(load(paste0(modelPath, '/tcmr_model_glmnet.rda')))
glm.model <- get(load(paste0(modelPath, '/tcmr_model_glm.rda')))
lda.model <- get(load(paste0(modelPath, '/tcmr_model_lda.rda')))
svmradial.model <- get(load(paste0(modelPath, '/tcmr_model_svmradial.rda')))
svmlinear.model <- get(load(paste0(modelPath, '/tcmr_model_svmlinear.rda')))
c5.model <- get(load(paste0(modelPath, '/tcmr_model_c5.rda')))
rf.model <- get(load(paste0(modelPath, '/tcmr_model_rf.rda')))
knn.model <- get(load(paste0(modelPath, '/tcmr_model_knn.rda')))
gbm.model <- get(load(paste0(modelPath, '/tcmr_model_gbm.rda')))
xgblinear.model <- get(load(paste0(modelPath, '/tcmr_model_xgblinear.rda')))
xgbtree.model <- get(load(paste0(modelPath, '/tcmr_model_xgbtree.rda')))
##-----------
## extract coefficients
coefs = coef(glm.model$finalModel)
top.genes <- names(coefs)
top.genes <- top.genes[grep("Intercept", top.genes, invert=TRUE)]
top.genes <- gsub("`", "", top.genes)
length(top.genes)
## Alberta
ua_counts <- read.csv("~/Dropbox/PTG/transcriptomics/nanostring/kidney/validation_cohorts/Alberta/alberta_counts_norm.csv", check.names=FALSE)
colnames(ua_counts)[1]<-"gene"
rownames(ua_counts) <- ua_counts$gene
ua_counts$gene <- NULL
ua_norm <- data.frame(t(ua_counts), check.names=F)
ua.df <- read.csv("~/Dropbox/PTG/transcriptomics/nanostring/kidney/validation_cohorts/Alberta/alberta_validation_cohort_clean.csv")
## MGH
mgh_counts <- read.csv("~/Dropbox/PTG/transcriptomics/nanostring/kidney/validation_cohorts/MGH/mgh_counts_norm.csv", check.names=FALSE)
colnames(mgh_counts)[1]<-"gene"
rownames(mgh_counts) <- mgh_counts$gene
mgh_counts$gene <- NULL
mgh_norm <- data.frame(t(mgh_counts), check.names=F)
mgh.df <- read.csv("~/Dropbox/PTG/transcriptomics/nanostring/kidney/validation_cohorts/MGH/mgh_validation_cohort_clean.csv")
## Alberta
ua.df <- ua.df[!ua.df$Dx %in% c("ABMR+TCMR", "ATI", "BKVN", "C4d-only", "CNIT", "GN", "Isolated-V", "MVI", "TCMR+MVI"),]
ua.df$Dx[ua.df$Dx %in% c("ABMR")]<-"amr"
ua.df$Dx[ua.df$Dx %in% c("TCMR")]<-"tcmr"
#ua.df$Dx[ua.df$Dx %in% c("ATI", "BKVN", "GN", "CNIT")]<-"other"
table(ua.df$Dx)
ua_norm <- ua_norm[rownames(ua_norm) %in% ua.df$ID,]
## MGH
#mgh.df <- mgh.df[mgh.df$Dx %in% c("CAMR", "NER", "TCMR1", "TCMR2"),]
mgh.df <- mgh.df[mgh.df$Dx %in% c("CAMR", "NER", "TCMR1", "TCMR2", "ATI"),]
mgh.df$Dx[mgh.df$Dx %in% c("CAMR")]<-"amr"
mgh.df$Dx[mgh.df$Dx %in% c("TCMR1", "TCMR2")]<-"tcmr"
mgh.df$Dx[mgh.df$Dx %in% c("NER")]<-"normal"
mgh.df$Dx[mgh.df$Dx %in% c("ATI")]<-"other"
table(mgh.df$Dx)
mgh_norm <- mgh_norm[rownames(mgh_norm) %in% mgh.df$ID,]
##--------------------------
## evaluate base model performance
##--------------------------
train_norm_sig <- train_norm[,colnames(train_norm) %in% top.genes]
#---------------
test_norm <- ptg_test_norm
test.df <- ref.df[ref.df$ID %in% rownames(ptg_test_norm),]
train_norm <- t(ruv.norm.endo.train)
ptg_test_norm <- t(ruv.norm.endo.test)
ref.df$Dx <- ifelse(ref.df$Dx %in% dx_amr, "amr",
ifelse(ref.df$Dx %in% dx_tcmr, "tcmr",
ifelse(ref.df$Dx %in% dx_normal, "normal", "other")))
##--------------------------
## evaluate base model performance
##--------------------------
train_norm_sig <- train_norm[,colnames(train_norm) %in% top.genes]
#---------------
test_norm <- ptg_test_norm
test.df <- ref.df[ref.df$ID %in% rownames(ptg_test_norm),]
test_norm_sig <- test_norm[,colnames(test_norm) %in% top.genes]
#training data includes genes in model only to allow data preprocessing
evalModels <- function(model.eval, trainingData, testData) {
model_name <- model.eval$method
print(model_name)
##----------
train.preds <- predict(model.eval, newdata=NULL, type="prob")
train.preds <- round(train.preds, 4)
train.preds$ID <- rownames(model.eval$trainingData)
train.preds <- merge(train.preds, ref.df[,c("ID", "Dx")], by="ID", all.x=TRUE)
##----------
test.preds <- predict(model.eval, newdata = testData, type="prob") #TEST
test.preds <- round(test.preds, 4)
test.preds$ID <- rownames(testData)
test.preds <- merge(test.preds, test.df[,c("ID", "Dx")], by="ID", all.x=TRUE)
##----------
## apply training set cutoff to test data
roc <- pROC::roc(ifelse(train.preds$Dx=="tcmr", 1, 0), train.preds$tcmr, quiet=TRUE)
train_coords <- coords(roc, x="best", input="threshold", best.method="youden", transpose=F)
train_metrics <- modelEval(true_values=ifelse(train.preds$Dx=="tcmr", 1, 0), predicted_values=train.preds$tcmr, threshold=train_coords$threshold, print.results=FALSE)
test_metrics <- modelEval(true_values=ifelse(test.preds$Dx=="tcmr", 1, 0), predicted_values=test.preds$tcmr, threshold=train_coords$threshold, print.results=FALSE)
train_metrics <- data.frame(train=t(round(train_metrics, 3)))
test_metrics <- data.frame(test=t(round(test_metrics, 3)))
colnames(train_metrics) <- paste0(model_name, "_train")
colnames(test_metrics) <- paste0(model_name, "_test")
## boxplots of predicted scores by Dx
dat <- test.preds
dat[,c("tcmr", "other")] <- dat[,c("tcmr", "other")]*100
boxplot_1 <- ggplot(data=dat, aes(x=Dx, y=tcmr)) +
ggtitle("tcmr scores") + ylim(c(0, 100)) +
ylab("molecular score (%)") + xlab("") +
geom_hline(yintercept=train_coords$threshold*100, linetype="dashed", color="slategray") +
geom_boxplot(color="steelblue4", fill="whitesmoke")
boxplot_0 <- ggplot(data=dat, aes(x=Dx, y=other)) +
ggtitle("Other scores") + ylim(c(0, 100)) +
ylab("molecular score (%)") + xlab("") +
geom_hline(yintercept=train_coords$threshold*100, linetype="dashed", color="slategray") +
geom_boxplot(color="steelblue4", fill="whitesmoke")
##-----
## confusion matrix
#ModelMetrics::confusionMatrix(ifelse(train.preds$Dx=="tcmr", 1, 0), train.preds$tcmr, cutoff=train_coords$threshold)
cmat <- ModelMetrics::confusionMatrix(ifelse(test.preds$Dx=="tcmr", 1, 0), test.preds$tcmr, cutoff=train_coords$threshold)
colnames(cmat) <- c(0, 1) #reference
rownames(cmat) <- c(0, 1) #predicted
##-----
## calibration curves:test data
tmp.preds <-  test.preds[,c("tcmr", "Dx")]
tmp.preds$Dx <- ifelse(tmp.preds$Dx=="tcmr", 1, 0)
calibration_plot(data = tmp.preds, obs = "Dx", pred = "tcmr", title="tcmr")
##-----
# add model name to score
colnames(train.preds) <- c("ID", paste0(colnames(train.preds)[grep("ID|Dx", colnames(train.preds), invert=T)], "_", model_name), "Dx")
colnames(test.preds) <- c("ID", paste0(colnames(test.preds)[grep("ID|Dx", colnames(test.preds), invert=T)], "_", model_name), "Dx")
# combine metrics
df_all <- cbind(train_metrics, test_metrics)
out_list <- list(df_all, train.preds, test.preds, boxplot_1, boxplot_0)
names(out_list) <- c("metrics", "train_scores", "test_scores", "tcmr_boxplot", "other_boxplot")
return(out_list)
}
glmnet.metrics <- evalModels(model.eval=glmnet.model, trainingData=train_norm_sig, testData=test_norm_sig)
glm.metrics <- evalModels(model.eval=glm.model, trainingData=train_norm_sig, testData=test_norm_sig)
lda.metrics <- evalModels(model.eval=lda.model, trainingData=train_norm_sig, testData=test_norm_sig)
svmradial.metrics <- evalModels(model.eval=svmradial.model, trainingData=train_norm_sig, testData=test_norm_sig)
svmlinear.metrics <- evalModels(model.eval=svmlinear.model, trainingData=train_norm_sig, testData=test_norm_sig)
gbm.metrics <- evalModels(model.eval=gbm.model, trainingData=train_norm_sig, testData=test_norm_sig)
xgblinear.metrics <- evalModels(model.eval=xgblinear.model, trainingData=train_norm_sig, testData=test_norm_sig) #overfitting
xgbtree.metrics <- evalModels(model.eval=xgbtree.model, trainingData=train_norm_sig, testData=test_norm_sig)
knn.metrics <- evalModels(model.eval=knn.model, trainingData=train_norm_sig, testData=test_norm_sig)
rf.metrics <- evalModels(model.eval=rf.model, trainingData=train_norm_sig, testData=test_norm_sig) #overfitting
c5.metrics <- evalModels(model.eval=c5.model, trainingData=train_norm_sig, testData=test_norm_sig) #overfitting
all.metrics <- cbind(glmnet.metrics$metrics, glm.metrics$metrics, svmradial.metrics$metrics, svmlinear.metrics$metrics, lda.metrics$metrics,
knn.metrics$metrics, rf.metrics$metrics, c5.metrics$metrics,
gbm.metrics$metrics, xgblinear.metrics$metrics, xgbtree.metrics$metrics)
# exclude overfitting and low performing
all.metrics <- all.metrics[,grep("rf|C5.0|gbm|xgbLinear|xgbTree|knn", colnames(all.metrics), invert=TRUE)]
train.metrics <- all.metrics[,grep("train", colnames(all.metrics))]
test.metrics <- all.metrics[,grep("test", colnames(all.metrics))]
test.metrics
## test data
score_list <- list(glmnet.metrics$test_scores, glm.metrics$test_scores, svmradial.metrics$test_scores, svmlinear.metrics$test_scores, lda.metrics$test_scores,
knn.metrics$test_scores, rf.metrics$test_scores, c5.metrics$test_scores,
gbm.metrics$test_scores, xgblinear.metrics$test_scores, xgbtree.metrics$test_scores)
all.scores <- Reduce(function(x,y) merge(x, y, all=TRUE, by=c("ID", "Dx")), score_list)
all.scores <- all.scores[,grep("rf|C5.0|gbm|xgbLinear|xgbTree|knn", colnames(all.scores), invert=TRUE)]
test.preds.ens <- all.scores[,c("ID", "Dx")]
test.preds.ens$tcmr_median <- apply(all.scores[,grep("tcmr", colnames(all.scores))], 1, median)
test.preds.ens <- merge(test.preds.ens, all.scores[,grep("ID|tcmr", colnames(all.scores))], by="ID")
outPath
write.csv(test.preds.ens, file=paste0(outPath, "/tcmr_model/test_tcmr_logit_preds.csv"), quote=F, row.names=F)
## train data
score_list <- list(glmnet.metrics$train_scores, glm.metrics$train_scores, svmradial.metrics$train_scores, svmlinear.metrics$train_scores, lda.metrics$train_scores,
knn.metrics$train_scores, rf.metrics$train_scores, c5.metrics$train_scores,
gbm.metrics$train_scores, xgblinear.metrics$train_scores, xgbtree.metrics$train_scores)
all.scores <- Reduce(function(x,y) merge(x, y, all=TRUE, by=c("ID", "Dx")), score_list)
all.scores <- all.scores[,grep("rf|C5.0|gbm|xgbLinear|xgbTree|knn", colnames(all.scores), invert=TRUE)]
train.preds.ens <- all.scores[,c("ID", "Dx")]
train.preds.ens$tcmr_median <- apply(all.scores[,grep("tcmr", colnames(all.scores))], 1, median)
train.preds.ens <- merge(train.preds.ens, all.scores[,grep("ID|tcmr", colnames(all.scores))], by="ID")
outPath
write.csv(train.preds.ens, file=paste0(outPath, "/tcmr_model/train_tcmr_logit_preds.csv"), quote=F, row.names=F)
## add ensemble performance metrics
roc <- pROC::roc(response=ifelse(train.preds.ens$Dx=="tcmr", 1, 0), predictor=train.preds.ens$tcmr_median, quiet=TRUE) #training data
ens_coords <- coords(roc, x="best", input="threshold", best.method="youden", transpose=F)
ens.train.metrics <- data.frame(median_train=round(t(modelEval(true_values=ifelse(train.preds.ens$Dx=="tcmr", 1, 0), predicted_values=train.preds.ens$tcmr_median, threshold=ens_coords$threshold, print.results=FALSE)), 3))
ens.test.metrics <- data.frame(median_test=round(t(modelEval(true_values=ifelse(test.preds.ens$Dx=="tcmr", 1, 0), predicted_values=test.preds.ens$tcmr_median, threshold=ens_coords$threshold, print.results=FALSE)), 3))
out.metrics <- cbind(train.metrics, ens.train.metrics)
out.metrics
write.csv(out.metrics, file=paste0(outPath, "/tcmr_model/train_amr_logit_metrics.csv"), quote=F, row.names=T)
out.metrics <- cbind(test.metrics, ens.test.metrics)
write.csv(all.metrics, file=paste0(outPath, "/tcmr_model/test_tcmr_logit_metrics.csv"), quote=F, row.names=T)
out.metrics
test_norm <- mgh_norm
test.df <- mgh.df
test_norm_sig <- test_norm[,colnames(test_norm) %in% top.genes]
#training data includes genes in model only to allow data preprocessing
evalModels <- function(model.eval, trainingData, testData) {
model_name <- model.eval$method
print(model_name)
##----------
train.preds <- predict(model.eval, newdata=NULL, type="prob")
train.preds <- round(train.preds, 4)
train.preds$ID <- rownames(model.eval$trainingData)
train.preds <- merge(train.preds, ref.df[,c("ID", "Dx")], by="ID", all.x=TRUE)
##----------
test.preds <- predict(model.eval, newdata = testData, type="prob") #TEST
test.preds <- round(test.preds, 4)
test.preds$ID <- rownames(testData)
test.preds <- merge(test.preds, test.df[,c("ID", "Dx")], by="ID", all.x=TRUE)
##----------
## apply training set cutoff to test data
roc <- pROC::roc(ifelse(train.preds$Dx=="tcmr", 1, 0), train.preds$tcmr, quiet=TRUE)
train_coords <- coords(roc, x="best", input="threshold", best.method="youden", transpose=F)
train_metrics <- modelEval(true_values=ifelse(train.preds$Dx=="tcmr", 1, 0), predicted_values=train.preds$tcmr, threshold=train_coords$threshold, print.results=FALSE)
test_metrics <- modelEval(true_values=ifelse(test.preds$Dx=="tcmr", 1, 0), predicted_values=test.preds$tcmr, threshold=train_coords$threshold, print.results=FALSE)
train_metrics <- data.frame(train=t(round(train_metrics, 3)))
test_metrics <- data.frame(test=t(round(test_metrics, 3)))
colnames(train_metrics) <- paste0(model_name, "_train")
colnames(test_metrics) <- paste0(model_name, "_test")
## boxplots of predicted scores by Dx
dat <- test.preds
dat[,c("tcmr", "other")] <- dat[,c("tcmr", "other")]*100
boxplot_1 <- ggplot(data=dat, aes(x=Dx, y=tcmr)) +
ggtitle("tcmr scores") + ylim(c(0, 100)) +
ylab("molecular score (%)") + xlab("") +
geom_hline(yintercept=train_coords$threshold*100, linetype="dashed", color="slategray") +
geom_boxplot(color="steelblue4", fill="whitesmoke")
boxplot_0 <- ggplot(data=dat, aes(x=Dx, y=other)) +
ggtitle("Other scores") + ylim(c(0, 100)) +
ylab("molecular score (%)") + xlab("") +
geom_hline(yintercept=train_coords$threshold*100, linetype="dashed", color="slategray") +
geom_boxplot(color="steelblue4", fill="whitesmoke")
##-----
## confusion matrix
#ModelMetrics::confusionMatrix(ifelse(train.preds$Dx=="tcmr", 1, 0), train.preds$tcmr, cutoff=train_coords$threshold)
cmat <- ModelMetrics::confusionMatrix(ifelse(test.preds$Dx=="tcmr", 1, 0), test.preds$tcmr, cutoff=train_coords$threshold)
colnames(cmat) <- c(0, 1) #reference
rownames(cmat) <- c(0, 1) #predicted
##-----
## calibration curves:test data
tmp.preds <-  test.preds[,c("tcmr", "Dx")]
tmp.preds$Dx <- ifelse(tmp.preds$Dx=="tcmr", 1, 0)
calibration_plot(data = tmp.preds, obs = "Dx", pred = "tcmr", title="tcmr")
##-----
# add model name to score
colnames(train.preds) <- c("ID", paste0(colnames(train.preds)[grep("ID|Dx", colnames(train.preds), invert=T)], "_", model_name), "Dx")
colnames(test.preds) <- c("ID", paste0(colnames(test.preds)[grep("ID|Dx", colnames(test.preds), invert=T)], "_", model_name), "Dx")
# combine metrics
df_all <- cbind(train_metrics, test_metrics)
out_list <- list(df_all, train.preds, test.preds, boxplot_1, boxplot_0)
names(out_list) <- c("metrics", "train_scores", "test_scores", "tcmr_boxplot", "other_boxplot")
return(out_list)
}
glmnet.metrics <- evalModels(model.eval=glmnet.model, trainingData=train_norm_sig, testData=test_norm_sig)
glm.metrics <- evalModels(model.eval=glm.model, trainingData=train_norm_sig, testData=test_norm_sig)
lda.metrics <- evalModels(model.eval=lda.model, trainingData=train_norm_sig, testData=test_norm_sig)
svmradial.metrics <- evalModels(model.eval=svmradial.model, trainingData=train_norm_sig, testData=test_norm_sig)
svmlinear.metrics <- evalModels(model.eval=svmlinear.model, trainingData=train_norm_sig, testData=test_norm_sig)
gbm.metrics <- evalModels(model.eval=gbm.model, trainingData=train_norm_sig, testData=test_norm_sig)
xgblinear.metrics <- evalModels(model.eval=xgblinear.model, trainingData=train_norm_sig, testData=test_norm_sig) #overfitting
xgbtree.metrics <- evalModels(model.eval=xgbtree.model, trainingData=train_norm_sig, testData=test_norm_sig)
knn.metrics <- evalModels(model.eval=knn.model, trainingData=train_norm_sig, testData=test_norm_sig)
rf.metrics <- evalModels(model.eval=rf.model, trainingData=train_norm_sig, testData=test_norm_sig) #overfitting
c5.metrics <- evalModels(model.eval=c5.model, trainingData=train_norm_sig, testData=test_norm_sig) #overfitting
all.metrics <- cbind(glmnet.metrics$metrics, glm.metrics$metrics, svmradial.metrics$metrics, svmlinear.metrics$metrics, lda.metrics$metrics,
knn.metrics$metrics, rf.metrics$metrics, c5.metrics$metrics,
gbm.metrics$metrics, xgblinear.metrics$metrics, xgbtree.metrics$metrics)
# exclude overfitting and low performing
all.metrics <- all.metrics[,grep("rf|C5.0|gbm|xgbLinear|xgbTree|knn", colnames(all.metrics), invert=TRUE)]
train.metrics <- all.metrics[,grep("train", colnames(all.metrics))]
test.metrics <- all.metrics[,grep("test", colnames(all.metrics))]
## test data
score_list <- list(glmnet.metrics$test_scores, glm.metrics$test_scores, svmradial.metrics$test_scores, svmlinear.metrics$test_scores, lda.metrics$test_scores,
knn.metrics$test_scores, rf.metrics$test_scores, c5.metrics$test_scores,
gbm.metrics$test_scores, xgblinear.metrics$test_scores, xgbtree.metrics$test_scores)
all.scores <- Reduce(function(x,y) merge(x, y, all=TRUE, by=c("ID", "Dx")), score_list)
all.scores <- all.scores[,grep("rf|C5.0|gbm|xgbLinear|xgbTree|knn", colnames(all.scores), invert=TRUE)]
test.preds.ens <- all.scores[,c("ID", "Dx")]
test.preds.ens$tcmr_median <- apply(all.scores[,grep("tcmr", colnames(all.scores))], 1, median)
test.preds.ens <- merge(test.preds.ens, all.scores[,grep("ID|tcmr", colnames(all.scores))], by="ID")
write.csv(test.preds.ens, file=paste0(outPath, "/tcmr_model/mgh_tcmr_logit_preds.csv"), quote=F, row.names=F)
## train data
score_list <- list(glmnet.metrics$train_scores, glm.metrics$train_scores, svmradial.metrics$train_scores, svmlinear.metrics$train_scores, lda.metrics$train_scores,
knn.metrics$train_scores, rf.metrics$train_scores, c5.metrics$train_scores,
gbm.metrics$train_scores, xgblinear.metrics$train_scores, xgbtree.metrics$train_scores)
all.scores <- Reduce(function(x,y) merge(x, y, all=TRUE, by=c("ID", "Dx")), score_list)
all.scores <- all.scores[,grep("rf|C5.0|gbm|xgbLinear|xgbTree|knn", colnames(all.scores), invert=TRUE)]
train.preds.ens <- all.scores[,c("ID", "Dx")]
train.preds.ens$tcmr_median <- apply(all.scores[,grep("tcmr", colnames(all.scores))], 1, median)
train.preds.ens <- merge(train.preds.ens, all.scores[,grep("ID|tcmr", colnames(all.scores))], by="ID")
## add ensemble performance metrics
roc <- pROC::roc(response=ifelse(train.preds.ens$Dx=="tcmr", 1, 0), predictor=train.preds.ens$tcmr_median, quiet=TRUE) #training data
ens_coords <- coords(roc, x="best", input="threshold", best.method="youden", transpose=F)
ens.train.metrics <- data.frame(median_train=round(t(modelEval(true_values=ifelse(train.preds.ens$Dx=="tcmr", 1, 0), predicted_values=train.preds.ens$tcmr_median, threshold=ens_coords$threshold, print.results=FALSE)), 3))
ens.test.metrics <- data.frame(median_test=round(t(modelEval(true_values=ifelse(test.preds.ens$Dx=="tcmr", 1, 0), predicted_values=test.preds.ens$tcmr_median, threshold=ens_coords$threshold, print.results=FALSE)), 3))
out.metrics <- cbind(train.metrics, ens.train.metrics)
out.metrics <- cbind(test.metrics, ens.test.metrics)
write.csv(all.metrics, file=paste0(outPath, "/tcmr_model/mgh_tcmr_logit_metrics.csv"), quote=F, row.names=T)
out.metrics
test_norm <- ua_norm
test.df <- ua.df
test_norm_sig <- test_norm[,colnames(test_norm) %in% top.genes]
#training data includes genes in model only to allow data preprocessing
evalModels <- function(model.eval, trainingData, testData) {
model_name <- model.eval$method
print(model_name)
##----------
train.preds <- predict(model.eval, newdata=NULL, type="prob")
train.preds <- round(train.preds, 4)
train.preds$ID <- rownames(model.eval$trainingData)
train.preds <- merge(train.preds, ref.df[,c("ID", "Dx")], by="ID", all.x=TRUE)
##----------
test.preds <- predict(model.eval, newdata = testData, type="prob") #TEST
test.preds <- round(test.preds, 4)
test.preds$ID <- rownames(testData)
test.preds <- merge(test.preds, test.df[,c("ID", "Dx")], by="ID", all.x=TRUE)
##----------
## apply training set cutoff to test data
roc <- pROC::roc(ifelse(train.preds$Dx=="tcmr", 1, 0), train.preds$tcmr, quiet=TRUE)
train_coords <- coords(roc, x="best", input="threshold", best.method="youden", transpose=F)
train_metrics <- modelEval(true_values=ifelse(train.preds$Dx=="tcmr", 1, 0), predicted_values=train.preds$tcmr, threshold=train_coords$threshold, print.results=FALSE)
test_metrics <- modelEval(true_values=ifelse(test.preds$Dx=="tcmr", 1, 0), predicted_values=test.preds$tcmr, threshold=train_coords$threshold, print.results=FALSE)
train_metrics <- data.frame(train=t(round(train_metrics, 3)))
test_metrics <- data.frame(test=t(round(test_metrics, 3)))
colnames(train_metrics) <- paste0(model_name, "_train")
colnames(test_metrics) <- paste0(model_name, "_test")
## boxplots of predicted scores by Dx
dat <- test.preds
dat[,c("tcmr", "other")] <- dat[,c("tcmr", "other")]*100
boxplot_1 <- ggplot(data=dat, aes(x=Dx, y=tcmr)) +
ggtitle("tcmr scores") + ylim(c(0, 100)) +
ylab("molecular score (%)") + xlab("") +
geom_hline(yintercept=train_coords$threshold*100, linetype="dashed", color="slategray") +
geom_boxplot(color="steelblue4", fill="whitesmoke")
boxplot_0 <- ggplot(data=dat, aes(x=Dx, y=other)) +
ggtitle("Other scores") + ylim(c(0, 100)) +
ylab("molecular score (%)") + xlab("") +
geom_hline(yintercept=train_coords$threshold*100, linetype="dashed", color="slategray") +
geom_boxplot(color="steelblue4", fill="whitesmoke")
##-----
## confusion matrix
#ModelMetrics::confusionMatrix(ifelse(train.preds$Dx=="tcmr", 1, 0), train.preds$tcmr, cutoff=train_coords$threshold)
cmat <- ModelMetrics::confusionMatrix(ifelse(test.preds$Dx=="tcmr", 1, 0), test.preds$tcmr, cutoff=train_coords$threshold)
colnames(cmat) <- c(0, 1) #reference
rownames(cmat) <- c(0, 1) #predicted
##-----
## calibration curves:test data
tmp.preds <-  test.preds[,c("tcmr", "Dx")]
tmp.preds$Dx <- ifelse(tmp.preds$Dx=="tcmr", 1, 0)
calibration_plot(data = tmp.preds, obs = "Dx", pred = "tcmr", title="tcmr")
##-----
# add model name to score
colnames(train.preds) <- c("ID", paste0(colnames(train.preds)[grep("ID|Dx", colnames(train.preds), invert=T)], "_", model_name), "Dx")
colnames(test.preds) <- c("ID", paste0(colnames(test.preds)[grep("ID|Dx", colnames(test.preds), invert=T)], "_", model_name), "Dx")
# combine metrics
df_all <- cbind(train_metrics, test_metrics)
out_list <- list(df_all, train.preds, test.preds, boxplot_1, boxplot_0)
names(out_list) <- c("metrics", "train_scores", "test_scores", "tcmr_boxplot", "other_boxplot")
return(out_list)
}
glmnet.metrics <- evalModels(model.eval=glmnet.model, trainingData=train_norm_sig, testData=test_norm_sig)
glm.metrics <- evalModels(model.eval=glm.model, trainingData=train_norm_sig, testData=test_norm_sig)
lda.metrics <- evalModels(model.eval=lda.model, trainingData=train_norm_sig, testData=test_norm_sig)
svmradial.metrics <- evalModels(model.eval=svmradial.model, trainingData=train_norm_sig, testData=test_norm_sig)
svmlinear.metrics <- evalModels(model.eval=svmlinear.model, trainingData=train_norm_sig, testData=test_norm_sig)
gbm.metrics <- evalModels(model.eval=gbm.model, trainingData=train_norm_sig, testData=test_norm_sig)
xgblinear.metrics <- evalModels(model.eval=xgblinear.model, trainingData=train_norm_sig, testData=test_norm_sig) #overfitting
xgbtree.metrics <- evalModels(model.eval=xgbtree.model, trainingData=train_norm_sig, testData=test_norm_sig)
knn.metrics <- evalModels(model.eval=knn.model, trainingData=train_norm_sig, testData=test_norm_sig)
rf.metrics <- evalModels(model.eval=rf.model, trainingData=train_norm_sig, testData=test_norm_sig) #overfitting
c5.metrics <- evalModels(model.eval=c5.model, trainingData=train_norm_sig, testData=test_norm_sig) #overfitting
all.metrics <- cbind(glmnet.metrics$metrics, glm.metrics$metrics, svmradial.metrics$metrics, svmlinear.metrics$metrics, lda.metrics$metrics,
knn.metrics$metrics, rf.metrics$metrics, c5.metrics$metrics,
gbm.metrics$metrics, xgblinear.metrics$metrics, xgbtree.metrics$metrics)
# exclude overfitting and low performing
all.metrics <- all.metrics[,grep("rf|C5.0|gbm|xgbLinear|xgbTree|knn", colnames(all.metrics), invert=TRUE)]
train.metrics <- all.metrics[,grep("train", colnames(all.metrics))]
test.metrics <- all.metrics[,grep("test", colnames(all.metrics))]
## test data
score_list <- list(glmnet.metrics$test_scores, glm.metrics$test_scores, svmradial.metrics$test_scores, svmlinear.metrics$test_scores, lda.metrics$test_scores,
knn.metrics$test_scores, rf.metrics$test_scores, c5.metrics$test_scores,
gbm.metrics$test_scores, xgblinear.metrics$test_scores, xgbtree.metrics$test_scores)
all.scores <- Reduce(function(x,y) merge(x, y, all=TRUE, by=c("ID", "Dx")), score_list)
all.scores <- all.scores[,grep("rf|C5.0|gbm|xgbLinear|xgbTree|knn", colnames(all.scores), invert=TRUE)]
test.preds.ens <- all.scores[,c("ID", "Dx")]
test.preds.ens$tcmr_median <- apply(all.scores[,grep("tcmr", colnames(all.scores))], 1, median)
test.preds.ens <- merge(test.preds.ens, all.scores[,grep("ID|tcmr", colnames(all.scores))], by="ID")
## train data
score_list <- list(glmnet.metrics$train_scores, glm.metrics$train_scores, svmradial.metrics$train_scores, svmlinear.metrics$train_scores, lda.metrics$train_scores,
knn.metrics$train_scores, rf.metrics$train_scores, c5.metrics$train_scores,
gbm.metrics$train_scores, xgblinear.metrics$train_scores, xgbtree.metrics$train_scores)
write.csv(test.preds.ens, file=paste0(outPath, "/tcmr_model/ua_tcmr_logit_preds.csv"), quote=F, row.names=F)
test.preds.ens
## train data
score_list <- list(glmnet.metrics$train_scores, glm.metrics$train_scores, svmradial.metrics$train_scores, svmlinear.metrics$train_scores, lda.metrics$train_scores,
knn.metrics$train_scores, rf.metrics$train_scores, c5.metrics$train_scores,
gbm.metrics$train_scores, xgblinear.metrics$train_scores, xgbtree.metrics$train_scores)
all.scores <- Reduce(function(x,y) merge(x, y, all=TRUE, by=c("ID", "Dx")), score_list)
all.scores <- all.scores[,grep("rf|C5.0|gbm|xgbLinear|xgbTree|knn", colnames(all.scores), invert=TRUE)]
train.preds.ens <- all.scores[,c("ID", "Dx")]
train.preds.ens$tcmr_median <- apply(all.scores[,grep("tcmr", colnames(all.scores))], 1, median)
train.preds.ens <- merge(train.preds.ens, all.scores[,grep("ID|tcmr", colnames(all.scores))], by="ID")
## add ensemble performance metrics
roc <- pROC::roc(response=ifelse(train.preds.ens$Dx=="tcmr", 1, 0), predictor=train.preds.ens$tcmr_median, quiet=TRUE) #training data
ens_coords <- coords(roc, x="best", input="threshold", best.method="youden", transpose=F)
ens.train.metrics <- data.frame(median_train=round(t(modelEval(true_values=ifelse(train.preds.ens$Dx=="tcmr", 1, 0), predicted_values=train.preds.ens$tcmr_median, threshold=ens_coords$threshold, print.results=FALSE)), 3))
ens.test.metrics <- data.frame(median_test=round(t(modelEval(true_values=ifelse(test.preds.ens$Dx=="tcmr", 1, 0), predicted_values=test.preds.ens$tcmr_median, threshold=ens_coords$threshold, print.results=FALSE)), 3))
out.metrics <- cbind(train.metrics, ens.train.metrics)
out.metrics <- cbind(test.metrics, ens.test.metrics)
write.csv(all.metrics, file=paste0(outPath, "/tcmr_model/ua_tcmr_logit_metrics.csv"), quote=F, row.names=T)
out.metrics
